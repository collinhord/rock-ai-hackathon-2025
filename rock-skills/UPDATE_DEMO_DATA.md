# Update Demo Data Pipeline

Quick reference for refreshing all demo data with latest LLM mapping results.

---

## 📊 **Data Status Check**

### Quick Status
```bash
cd /Users/collin.hord/Documents/GitHub/rock-ai-hackathon-2025/rock-skills

echo "=== LLM Mappings ==="
wc -l analysis/llm_skill_mappings.csv

echo "=== Master Concepts ==="
wc -l analysis/master-concepts.csv

echo "=== Variant Classification ==="
ls -lh analysis/outputs/variant-classification-report.csv 2>&1 || echo "❌ Not generated yet"
```

---

## 🔄 **Complete Data Refresh Pipeline**

Run these scripts in order to ensure the demo surfaces all your latest LLM mapping results:

### **1. Variant Classification** (Required for Variant Analysis page)
```bash
cd analysis
python3 variant_classifier.py
```

**What it does:**
- Analyzes all ROCK ELA skills (8,000+)
- Identifies **State A** (cross-state variants): TX/CA/VA skills for same concept
- Identifies **State B** (grade progressions): K-12 progression chains
- Marks unique skills with no variants

**Output:**
- `analysis/outputs/variant-classification-report.csv`
- Enables "🔗 Variant Analysis" page in demo

**Time:** ~2-5 minutes  
**Dependencies:** `taxonomy.db`

---

### **2. LLM Batch Mapping** (Optional - if you have unmapped skills)

If you want to map additional skills:

```bash
cd analysis

# Check remaining unmapped skills
python3 check_remaining.py

# Run batch mapping for new skills
python3 scripts/batch_map_skills.py \
    --content-area "English Language Arts" \
    --checkpoint-interval 10 \
    --output-dir ./outputs/my_new_batch \
    --skip-existing llm_skill_mappings.csv
```

**What it does:**
- Uses semantic similarity + Claude Sonnet 4.5
- Maps ROCK skills to Science of Reading taxonomy
- Appends to `llm_skill_mappings.csv`

**Time:** ~20-40 minutes per 150 skills  
**Cost:** ~$1.50-4.50 per 150 skills

---

### **3. Redundancy Analysis** (Optional - for updated fragmentation metrics)

If you've added new master concepts or want fresh visualizations:

```bash
cd analysis
jupyter notebook redundancy-analysis.ipynb
# In browser: Kernel → Restart & Run All
```

**What it does:**
- Analyzes skill fragmentation patterns
- Updates `master-concepts.csv`
- Generates `fragmentation-examples.csv`
- Creates distribution charts

**Output:**
- Updated metrics for "📊 Redundancy Visualizer" page
- PNG charts (optional)

**Time:** ~2-3 minutes

---

## 🎯 **For Hackathon Demo (Recommended Sequence)**

### Minimum Required (First Time)
```bash
cd /Users/collin.hord/Documents/GitHub/rock-ai-hackathon-2025/rock-skills

# 1. Generate variant classification
cd analysis && python3 variant_classifier.py && cd ..

# 2. Restart Streamlit app
pkill -f streamlit
cd poc
python3 -m streamlit run skill_bridge_app.py --server.headless true --server.port 8501
```

### Full Refresh (After New LLM Mappings)
```bash
cd /Users/collin.hord/Documents/GitHub/rock-ai-hackathon-2025/rock-skills

# 1. Run variant classifier
cd analysis && python3 variant_classifier.py && cd ..

# 2. Update redundancy analysis (optional)
cd analysis && jupyter notebook redundancy-analysis.ipynb
# Kernel → Restart & Run All → Save & Close
cd ..

# 3. Restart Streamlit
pkill -f streamlit
cd poc
python3 -m streamlit run skill_bridge_app.py --server.headless true --server.port 8501
```

---

## 📋 **What Each Demo Page Needs**

| Demo Page | Required Data | Generated By |
|-----------|---------------|--------------|
| **🎯 Content Scaling Simulator** | `poc/mock_data/content_library.csv` | ✅ Pre-generated (mock data) |
| | `poc/mock_data/tagging_scenarios.csv` | ✅ Pre-generated (mock data) |
| **🔍 Master Concept Browser** | `analysis/llm_skill_mappings.csv` | ✅ You have (1,600 skills) |
| | `POC_science_of_reading_literacy_skills_taxonomy.csv` | ✅ Pre-generated |
| **📊 Redundancy Visualizer** | `analysis/master-concepts.csv` | ✅ You have (16 concepts) |
| **🔗 Variant Analysis** | `analysis/outputs/variant-classification-report.csv` | ⚠️ **Run `variant_classifier.py`** |
| **🔎 Skill Deep Dive** | `taxonomy.db` | ✅ Pre-generated |
| | `llm_skill_mappings.csv` | ✅ You have |

---

## 🚨 **Troubleshooting**

### "Variant classification data not available"
**Cause:** `variant-classification-report.csv` doesn't exist

**Fix:**
```bash
cd analysis
python3 variant_classifier.py
```

### "LLM skill mappings not yet available"
**Cause:** `llm_skill_mappings.csv` is empty or missing

**Fix:**
```bash
cd analysis
python3 scripts/batch_map_skills.py --content-area "English Language Arts" --checkpoint-interval 10 --output-dir ./outputs/demo_batch
```

### "No data available. Run redundancy analysis first"
**Cause:** `master-concepts.csv` is empty

**Fix:**
```bash
cd analysis
jupyter notebook redundancy-analysis.ipynb
# Run all cells
```

### Streamlit Shows Old Data
**Cause:** Streamlit cache

**Fix:**
```bash
pkill -f streamlit
streamlit cache clear
cd poc
python3 -m streamlit run skill_bridge_app.py --server.headless true --server.port 8501
```

---

## ✅ **Verification**

After running scripts, verify all data is ready:

```bash
cd /Users/collin.hord/Documents/GitHub/rock-ai-hackathon-2025/rock-skills
python3 scripts/verify_data_integrity.py
```

All checks should pass ✅

---

## 📈 **Current Data Metrics**

Based on your latest LLM mapping runs:

- **Mapped Skills:** 1,600 ELA skills
- **Master Concepts:** 16 literacy concepts
- **Batch Outputs:** 8 completed runs
- **Variant Classification:** ⏳ Run `variant_classifier.py` to generate

---

**Last Updated:** October 15, 2025  
**Project:** ROCK Skills Taxonomy Bridge  
**Demo:** http://localhost:8501

