# Taxonomy Viewer & Base Skills Demo Script

**Duration:** 15 minutes (demo) + 30 minutes (Q&A)  
**Audience:** Stakeholders, decision-makers, technical team  
**Goal:** Demonstrate how Base Skills + Specifications + Taxonomy enable superior skill discovery and organization

---

## Pre-Demo Checklist (5 minutes before)

- [ ] Navigate to project directory: `cd /Users/collin.hord/Documents/GitHub/rock-ai-hackathon-2025/rock-skills/poc`
- [ ] Start Streamlit app: `streamlit run skill_bridge_app.py`
- [ ] Verify app loads successfully (should open in browser)
- [ ] Check all data loads: Base Skills Explorer shows 59 base skills
- [ ] Test one filter in Interactive Explorer (confirm data displays)
- [ ] Have backup screenshots ready (in case of technical issues)
- [ ] Open this script in a separate window for reference

---

## Demo Flow Overview

**Total Time: 12-15 minutes**

1. **Opening: The Problem** (2 min)
2. **Solution Overview** (2 min)
3. **Live Demo: Base Skills Explorer** (4 min)
4. **Live Demo: Specifications Showcase** (2 min)
5. **Live Demo: Taxonomy-Powered Discovery** (3 min)
6. **Impact Summary** (2 min)

---

## Part 1: Opening - The Problem (2 minutes)

### Starting Position

**Navigate to:** Executive View page (should be default)

### Script:

> "Good morning everyone. Today I'm going to show you how we can solve a critical problem in our ROCK skills systemâ€”one that's costing us hundreds of hours and limiting our ability to scale content across states."

**Scroll to "The Problem: Skill Fragmentation" section**

> "Here's the core issue: We have **[READ METRIC]** ROCK skills in our database, but the reality is that many of these skills teach the exact same concept. They're just worded differently because they come from different state standards."

**Point to the phoneme blending example visualization**

> "Look at this example: 'Phoneme Blending.' This is ONE learning concept, but it appears as EIGHT different skills across statesâ€”Texas calls it one thing, California another, Common Core yet another. Without any linking metadata."

### Key Talking Points:

- **Business Impact**: Content creators either duplicate work 8x OR only cover one state (8% coverage)
- **Discovery Problem**: Teachers can't find relevant content from other states
- **Data Problem**: Can't aggregate analytics across conceptually equivalent skills
- **Cost**: 80-90% efficiency loss in content scaling

### Transition:

> "So how do we fix this? Through a three-part solution: Base Skills, Specifications, and Taxonomy."

---

## Part 2: Solution Overview (2 minutes)

### Navigate to:

Stay on Executive View, scroll to "The Solution" section

### Script:

> "Our solution has three integrated levels, and I'll show you each one live:"

**Point to the three-column architecture diagram**

> "**Level 1: Specifications.** We use AI to extract structured metadata from skill descriptionsâ€”things like cognitive demand, text type, complexity. This is the foundation that lets us understand what a skill actually teaches."

> "**Level 2: Base Skills.** We use those specifications to identify which ROCK skills teach the same fundamental competency. Instead of 8 fragmented skills, we have 1 base skill with 8 variants."

> "**Level 3: Taxonomy Mapping.** We map base skills to the Science of Reading taxonomyâ€”a research-backed framework. This enables precise, multi-dimensional filtering."

### Key Talking Points:

- **Specifications = Understanding**: 23 metadata fields per skill
- **Base Skills = Deduplication**: ~6x redundancy reduction
- **Taxonomy = Organization**: Science-based classification enables precise discovery

### Transition:

> "Let me show you this live. I'm going to take you through our working prototype."

---

## Part 3: Live Demo - Base Skills Explorer (4 minutes)

### Navigate to:

Click **"âš¡ Base Skills Explorer"** in sidebar

### Script:

> "First, let's look at Base Skills. This is where we've collapsed redundant ROCK skills into fundamental learning competencies."

**Point to the metrics at the top**

> "We currently have **[READ: Total Base Skills]** base skills that represent **[READ: Total ROCK Skills Collapsed]** ROCK skills. That's an average redundancy ratio of **[READ: X.X]x**. In other words, every base skill represents about 6-7 equivalent ROCK skills from different states."

**Scroll to visualization section**

> "Here's what that redundancy looks like visually. This bar chart shows our top 15 base skills by how many ROCK skills they collapse."

**Hover over highest bar**

> "This base skillâ€”**[READ NAME]**â€”represents **[READ NUMBER]** different ROCK skills. Same learning concept, just described differently across states."

**Scroll to pie chart**

> "We can also see the distribution by cognitive categoryâ€”comprehension, analysis, application, etc. This is important because it helps us organize skills by learning level."

### Interactive Part:

> "Let me show you the interactive browser. Say I want to find base skills related to phonological awareness..."

**Type "phoneme" or "sound" in search box**

> "I'll search for 'phoneme'... and here we get all base skills related to phoneme awareness."

**Click to expand one base skill**

> "When I expand one, you can see:
> - The base skill name and description
> - How many ROCK skills it represents
> - Sample ROCK skills from our dataset
> - Grade levels and cognitive demand"

### Key Talking Points:

- **Visual Impact**: Show the redundancy visually (big bars = big redundancy)
- **Efficiency**: "Instead of tagging content 8 times, tag once to the base skill"
- **Discovery**: "Teachers can now find all state variants automatically"

### Transition:

> "Now, how do we identify these base skills? Through specifications."

---

## Part 4: Live Demo - Specifications Showcase (2 minutes)

### Navigate to:

Scroll down on Base Skills Explorer page to "How Specifications Reveal Base Skills" section

### Script:

> "Specifications are structured metadata we extract from ROCK skill descriptions using NLP and AI."

**Expand one of the example skills**

> "Look at these three skills from our dataset. On the left, you see structural specificationsâ€”the actions (identify, describe), targets (plot, characters), and qualifiers (basic, key). On the right, educational specificationsâ€”text type (fictional), cognitive demand (comprehension), task complexity (basic)."

**Point to the comparison**

> "Notice how similar these specifications are? That's how we know these skills teach related base concepts. This isn't manualâ€”it's automated through our extraction pipeline."

**Scroll to specification statistics table**

> "We've extracted specifications for **[READ: X]** skills with an average coverage of **[READ: X%]** across all fields. This gives us the metadata richness we need for intelligent grouping and filtering."

### Key Talking Points:

- **Automation**: "This runs automaticallyâ€”takes about 12-15 minutes for 300 skills"
- **Cost**: "About $9-12 for 3,000 skills via AI, vs. $30,000+ for human annotation"
- **Accuracy**: "90%+ accuracy with validation checkpoints"
- **Scale**: "Can process all 8,000+ ROCK skills"

### Transition:

> "Now let's see the real powerâ€”taxonomy-enabled discovery."

---

## Part 5: Live Demo - Taxonomy-Powered Discovery (3 minutes)

### Navigate to:

Click **"ðŸ§­ Interactive Explorer"** in sidebar, then select **"ðŸŽ¯ Skill Search & Inspector"**

### Script:

> "This is where everything comes together. Watch what happens when we combine specifications with taxonomy."

**Click on "Why Taxonomy-Powered Discovery?" expander**

> "Traditional text search gives you hundreds of irrelevant results, no grade precision, and requires manual filtering. Taxonomy-powered discovery gives you instant, precise results."

### Live Filtering Demo:

> "Let me show you. Say I'm a curriculum developer looking for **phonological awareness skills for K-2 students**."

**Perform the following actions:**

1. **Taxonomy Strand**: Select "Word Recognition" (if available)
2. **Grade Band**: Select "K-2"
3. **Search box**: Type "phoneme" or "sound"

**As results appear:**

> "Look at thisâ€”I go from **[READ: Total Skills]** down to **[READ: Filtered Count]** highly relevant skills. That's a **[READ: Noise Reduction %]%** noise reduction."

**Scroll through results table**

> "And every result here is:
> - Grade-appropriate (K-2)
> - Taxonomically correct (Word Recognition)
> - Phonologically relevant"

### Advanced Filtering Demo (if time permits):

> "But we can go even deeper. Let me add **cognitive demand filters**..."

**Select "Cognitive Demand": comprehension**

**Select "Text Type": fictional (if available)**

> "Now I'm filtering by multiple dimensions at onceâ€”grade band, taxonomy, cognitive level, AND text type. This level of precision was impossible before."

### Key Talking Points:

- **Time Savings**: "45 minutes of manual filtering â†’ 30 seconds automated"
- **Precision**: "95%+ relevance vs. 40% with text search"
- **Scalability**: "Works across all 8,000+ skills"
- **Discovery**: "Find skills you'd never discover with keyword search"

### Transition:

> "Let me show you one more quick thingâ€”pre-built scenarios."

---

## Part 6: Quick Scenarios Peek (1 minute) - OPTIONAL

### Navigate to:

Click **"ðŸ“– Demo Scenarios"** in sidebar

### Script:

> "We've built three pre-configured scenarios that demonstrate common use cases:"

**Point to scenario selector**

> "Scenario A: Finding phonological awareness for K-2â€”exactly what we just did"
> "Scenario B: Analysis-level comprehension for fiction"
> "Scenario C: Cross-state discovery"

**Select Scenario C and expand example**

> "Scenario C shows the cross-state problem I mentioned earlier. One base skill with **[READ NUMBER]** state variants. Tag content once, discoverable by all variants. That's the efficiency gain."

### Transition:

> "Let me wrap up with the impact."

---

## Part 7: Impact Summary (2 minutes)

### Navigate to:

Return to Executive View page (or stay on current page)

### Script:

> "Let me summarize what we've shown you today:"

### Key Metrics to Emphasize:

**Write these on whiteboard or screen share:**

1. **Redundancy Reduction**: 6-8x collapse (337 skills â†’ 59 base skills)
2. **Time Savings**: 45 min â†’ 30 sec for skill discovery (99% reduction)
3. **Cost Efficiency**: $9-12 for 3,000 skills vs. $30,000 human annotation
4. **Coverage**: 8% â†’ 100% cross-state content discoverability
5. **Precision**: 95%+ relevance vs. 40% with traditional search

### The Value Proposition:

> "Here's what this enables for our business:
>
> **For Content Teams**: Tag content once, discoverable across all states. 80-90% efficiency gain.
>
> **For Educators**: Find exactly the right skills in seconds, not hours. Discover cross-state content they never knew existed.
>
> **For Data Science**: Aggregate analytics at the base skill level, not fragmented across 8 state-specific variants.
>
> **For Product**: Enable semantic search, adaptive learning, and learning progressionsâ€”features that were previously impossible."

### What's Next:

> "This is a working prototype using our filtered dataset of 336 skills. The infrastructure is ready to scale to all 8,000+ ROCK skills. The extraction pipeline is production-ready. The taxonomy is validated against the Science of Reading research."

---

## Q&A Preparation (30 minutes)

### Expected Questions & Answers:

#### "How accurate is the AI extraction?"

> "90%+ accuracy for educational metadata, 98%+ for structural elements. We use a hybrid approachâ€”spaCy for deterministic parsing, Claude for contextual understanding, and validation checkpoints. Low-confidence extractions are flagged for human review."

#### "What's the cost to scale this?"

> "For 3,000 skills: ~$9-12 and 2-3 hours processing time. For all 8,000+ ROCK skills: ~$30-40 and 6-8 hours. Compare that to $30,000+ for human annotation that would take weeks."

#### "Can this work for Math skills too?"

> "Yes. The same extraction pipeline works for Mathâ€”we just need to adjust the specification schema slightly. The taxonomy would map to a Math learning progressions framework instead of Science of Reading."

#### "How do we maintain this as skills change?"

> "The pipeline is incrementalâ€”we can reprocess individual skills or batches as they're updated. New skills get specifications extracted automatically. The base skill grouping uses embeddings, so similar skills cluster naturally."

#### "What if two skills are similar but NOT equivalent?"

> "That's why we have confidence scores and validation checkpoints. The system flags borderline cases for human review. We can also define relationship typesâ€”'prerequisite', 'related', 'variant', etc."

#### "How does this integrate with Star?"

> "Base skills become a bridging layerâ€”content tagged to a base skill is automatically discoverable via all its ROCK skill variants. Star content tags remain at the ROCK skill level, but discovery happens through the base skill bridge."

#### "What's the timeline to production?"

> "The pipeline is production-ready now. We need:
> 1. Full dataset processing: 1 week
> 2. Expert validation of base skills: 2 weeks
> 3. API integration: 2-3 weeks
> 4. User testing: 2 weeks
> 
> Total: 6-8 weeks to production-ready API."

---

## Backup Plans

### If Live Demo Fails:

1. **Use Screenshots**: Navigate to backup folder with pre-captured images
2. **Use Notebook**: Open `analysis/hackathon_demo.ipynb` for code-based demo
3. **Narrate from Script**: Walk through the flow conceptually using this script

### If Data Doesn't Load:

> "Let me show you the underlying data files instead..."

Navigate to:
- `/taxonomy/base_skills/` - Show JSON files
- `/analysis/outputs/filtered_enhanced_metadata/` - Show CSV
- Explain: "The app is just a visualization layer on top of these data pipelines"

### If Questions Stall:

**Backup demo topics:**

1. Show the Three-Level Deep Dive page (MACRO/MID/MICRO)
2. Show the Validation Dashboard (if validation results exist)
3. Show the taxonomy hierarchy in Taxonomy Navigator
4. Show the concept guide document

---

## Post-Demo Actions

1. **Share Demo Link**: 
   ```
   git commit -m "Complete taxonomy demo implementation"
   git push
   ```
   
2. **Share Access**: Provide stakeholders with:
   - Link to GitHub repo
   - Demo script (this file)
   - QUICKSTART.md for running locally

3. **Gather Feedback**: 
   - What questions came up?
   - What features resonated most?
   - What concerns were raised?

4. **Follow-up**: Schedule technical deep-dive if needed

---

## Key Messages to Reinforce

1. **This solves a real, expensive problem**: 80-90% efficiency loss â†’ 100% efficiency
2. **The tech is proven**: Working prototype, production-ready pipeline
3. **The cost is reasonable**: $9-12 per 3,000 skills vs. $30,000 human annotation
4. **This unlocks new features**: Semantic search, adaptive learning, learning progressions
5. **The science is solid**: Grounded in Science of Reading research
6. **This scales**: Can process all 8,000+ skills, extends to Math

---

## Contact for Questions

- **Technical Questions**: [Your Name/Team]
- **Business Questions**: [Stakeholder Name]
- **Demo Issues**: Refer to `/rock-skills/poc/README.md`

---

**Good luck with the demo!** ðŸš€

